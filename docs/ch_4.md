# 📘 임베딩 문서란?

## 🔹 정의
- 문서를 벡터(숫자 배열)로 변환한 것
- 각 문장의 의미를 고차원 벡터 공간에 위치시키는 방식
- 벡터 간의 거리를 통해 문맥적 유사성을 계산할 수 있음

예를 들어:

| 문장           | 임베딩 벡터 (간략 예시)            |
| ------------ | ------------------------- |
| "고양이는 귀엽다"   | \[0.12, 0.98, -0.33, ...] |
| "강아지는 사랑스럽다" | \[0.10, 0.95, -0.31, ...] |

→ 두 문장은 유사한 의미로 판단됨

---

## 🧠 임베딩 기반 LLM 활용 방식

### 🧰 사용 구조 (예: LangChain Retrieval)

1. 문서 → 조각으로 나누기 (text_splitter)
2. 각 조각을 벡터화 (OpenAIEmbeddings)
3. 벡터 DB에 저장 (FAISS, Pinecone, 등)
4. 사용자가 질문하면, 해당 질문도 벡터화해서
5. 가장 유사한 문서 조각 검색
6. 검색된 문서 + 프롬프트로 LLM 질의

```text
[질문]
   ↓
[문서 벡터 검색 (Top-k)]
   ↓
[문서 + 프롬프트] → LLM → 답변
```

---

## 🆚 일반 프롬프트 방식과 비교

| 구분     | 임베딩 문서 기반                           | 일반 프롬프트 방식            |
| ------ | ----------------------------------- | --------------------- |
| 정보 출처  | 외부 문서(DB, 파일 등)                     | 오직 프롬프트 내에 포함된 정보     |
| 확장성    | 수천\~수만 문서도 대응 가능 (벡터 검색)            | 길이 제한 있음 (4k\~32k 토큰) |
| 검색 정확도 | 의미 기반 검색 (의미가 비슷하면 검색됨)             | 명시적으로 적어줘야 함          |
| 예시     | "사전 지식 없는 질문에 대해 FAQ 문서 기반으로 응답 생성" | "주어진 질문에 대해 직접 응답"    |

---

## 💡 예시

1. 일반 프롬프트

```text
Q: What is LangChain?
A: LangChain is a framework for building applications with LLMs.
```

2. 임베딩 기반 프롬프트

```text
User Question: "What does LangChain do?"
→ (임베딩 검색) 관련 문서 조각 찾아서

Prompt:
Context: LangChain is a framework for building applications with LLMs.
Question: What does LangChain do?
Answer:
```

---

## 🔍 대표적인 벡터 저장소 종류 및 비교

| 이름                                 | 유형       | 운영 방식          | 주요 특징                                                          | 추천 사용 상황                                     |
| ---------------------------------- | -------- | -------------- | -------------------------------------------------------------- | -------------------------------------------- |
| **FAISS**                          | 라이브러리    | 로컬 (In-memory) | - Meta에서 개발<br>- 빠른 검색<br>- 설치 간단<br>- **오픈소스**                | - 개인 프로젝트<br>- 빠른 프로토타이핑<br>- 서버 없는 환경       |
| **Pinecone**                       | SaaS     | 클라우드 기반        | - Fully managed<br>- 스케일링 자동<br>- 실시간 검색 성능 우수                 | - 운영 복잡도 최소화<br>- 대규모 사용자 대상<br>- LLM 제품 상용화 |
| **Weaviate**                       | 서버형/클라우드 | 독립 서버 or SaaS  | - REST/GraphQL API 제공<br>- 벡터 + 메타데이터 관리 가능<br>- 내부 임베딩 지원도 가능 | - 복합 질의 (벡터+속성 조건)<br>- 오픈소스 + 클라우드          |
| **Qdrant**                         | 서버형/클라우드 | 독립 서버 or SaaS  | - 고성능 Rust 기반<br>- Filter 조건 지원<br>- 다양한 언어 클라이언트              | - 대용량 + 정밀 조건 질의                             |
| **Milvus**                         | 서버형      | 클러스터링 가능       | - 벡터 데이터 전용 DB<br>- 매우 대규모 확장성<br>- GPU 가속 지원                  | - 수억 개 벡터<br>- 대규모 ML 시스템                    |
| **Redis Vector Similarity Search** | 인메모리 DB  | 온프레미스 or 클라우드  | - Redis 내에서 벡터 처리<br>- 빠른 처리 + TTL 지원                          | - 임시 저장<br>- 캐시 기반 벡터 질의                     |

### 🧠 선택 기준 요약

| 기준                   | 추천                   |
| -------------------- | -------------------- |
| **개인 개발/테스트**        | `FAISS`              |
| **빠른 배포 + 무설정 클라우드** | `Pinecone`           |
| **복합 검색 (속성 + 벡터)**  | `Weaviate`, `Qdrant` |
| **수천만\~수억 벡터**       | `Milvus`, `Qdrant`   |
| **임베딩 + 캐시 목적**      | `Redis Vector`       |


---

## ✅ 언제 임베딩을 써야 할까?

| 상황                                   | 추천 여부           |
| ------------------------------------ | --------------- |
| 문서 기반 질의 응답 (e.g. 사내 문서 검색)          | ✅ 적극 추천         |
| 단일 질문/답변 위주 챗봇                       | ❌ 일반 프롬프트가 더 간단 |
| RAG (Retrieval-Augmented Generation) | ✅ 핵심 사용 방식      |

---

## 