# ğŸ§  LangChain `BaseChatModel` í•™ìŠµ ì •ë¦¬

## ğŸ“Œ ê°œìš”

`BaseChatModel`ì€ LangChainì—ì„œ ëª¨ë“  **Chat ê¸°ë°˜ LLM ëª¨ë¸**ì„ ì¶”ìƒí™”í•˜ê¸° ìœ„í•œ **ê¸°ë³¸ ì¶”ìƒ í´ë˜ìŠ¤**ì…ë‹ˆë‹¤. `ChatOpenAI`, `ChatAnthropic`, `ChatMistral` ë“± ëª¨ë“  LLMì€ ì´ í´ë˜ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„ë©ë‹ˆë‹¤.

```python
class BaseChatModel(BaseLanguageModel[BaseMessage], ABC):
```

- Runnableì„ ê°„ì ‘ ìƒì†í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ë¡œ ë™ì‘í•¨
- í•µì‹¬ ë©”ì„œë“œ: _generate(), _call(), invoke()

---

## ğŸ“š ìƒì† êµ¬ì¡°

```text
ChatOpenAI
 â””â”€â”€ BaseChatOpenAI
      â””â”€â”€ BaseChatModel
           â””â”€â”€ BaseLanguageModel
                â””â”€â”€ RunnableSerializable
                     â””â”€â”€ Runnable
```

- invoke, __call__, batch, stream ë“±ì˜ ë©”ì„œë“œëŠ” Runnableì—ì„œ ì œê³µë¨

---

## ğŸ”§ í•µì‹¬ êµ¬í˜„ ë©”ì„œë“œ

| ë©”ì„œë“œ                    | ì„¤ëª…                                             | í•„ìˆ˜ ì—¬ë¶€ |
| ---------------------- | ---------------------------------------------- | ----- |
| `_generate(messages)`  | ì‹¤ì œ LLM í˜¸ì¶œ ë° ê²°ê³¼ ìƒì„±                              | âœ… í•„ìˆ˜  |
| `_llm_type` (property) | ëª¨ë¸ íƒ€ì… ëª…ì‹œ (`"openai-chat"`, `"anthropic"`, ...) | âœ… í•„ìˆ˜  |
| `_identifying_params`  | íŠ¸ë ˆì´ì‹±/ë¡œê¹…ìš© íŒŒë¼ë¯¸í„° ë°˜í™˜                               | â­• ì„ íƒ  |
| `_stream(messages)`    | ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬                                     | â­• ì„ íƒ  |
| `_agenerate()`         | ë¹„ë™ê¸° LLM ì‘ë‹µ ìƒì„±                                  | â­• ì„ íƒ  |
| `_astream()`           | ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬                                    | â­• ì„ íƒ  |


---

## ğŸš€ ì‹¤í–‰ íë¦„ (í˜¸ì¶œ ìŠ¤íƒ)

```python
llm = ChatOpenAI(...)
llm.invoke(input)
```

### ë‚´ë¶€ íë¦„

```text
invoke(input)
 â†’ Runnable.invoke()
   â†’ _call_with_config(func=self._call, input)
     â†’ context.run(call_func_with_variable_args, self._call, ...)
       â†’ self._call(input)
         â†’ self._generate(messages)
           â†’ openai.ChatCompletion.create(...)
```

- invoke()ì™€ __call__()ì€ ë™ì¼í•œ ë™ì‘ì„ í•¨
- self._callì€ BaseChatModelì—ì„œ êµ¬í˜„ë¨

---

## âš™ï¸ Imperative Methods (ì¦‰ì‹œ ì‹¤í–‰ ë©”ì„œë“œ)

| ë©”ì„œë“œ                     | ì…ë ¥                                    | ì¶œë ¥                           | ì„¤ëª…        |
| ----------------------- | ------------------------------------- | ---------------------------- | --------- |
| `invoke()`              | `str`, `BaseMessage`, `PromptValue` ë“± | `BaseMessage`                | ë‹¨ì¼ ì‹¤í–‰     |
| `ainvoke()`             | ìœ„ì™€ ë™ì¼                                 | `BaseMessage`                | ë¹„ë™ê¸° ì‹¤í–‰    |
| `stream()`              | ì…ë ¥                                    | `Iterator[BaseMessageChunk]` | ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰   |
| `astream()`             | ì…ë ¥                                    | `AsyncIterator[...]`         | ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë°  |
| `batch()`               | ì—¬ëŸ¬ ì…ë ¥                                 | `List[BaseMessage]`          | ë³‘ë ¬ ì‹¤í–‰     |
| `abatch()`              | ì—¬ëŸ¬ ì…ë ¥                                 | `List[BaseMessage]`          | ë¹„ë™ê¸° ë³‘ë ¬ ì‹¤í–‰ |
| `batch_as_completed()`  | ì—¬ëŸ¬ ì…ë ¥                                 | ì™„ë£Œ ìˆœì„œëŒ€ë¡œ ë°˜í™˜                   | ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼  |
| `abatch_as_completed()` | ì—¬ëŸ¬ ì…ë ¥                                 | ì™„ë£Œ ìˆœì„œëŒ€ë¡œ ë¹„ë™ê¸° ë°˜í™˜               | ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ |


---

## ğŸ§± Declarative Methods (êµ¬ì„± ë° ë˜í¼ ë©”ì„œë“œ)

| ë©”ì„œë“œ                              | ì„¤ëª…                  |
| -------------------------------- | ------------------- |
| `with_retry()`                   | ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„ ê¸°ëŠ¥ ì¶”ê°€   |
| `with_fallbacks([ëª¨ë¸])`           | ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ëª¨ë¸ ì‚¬ìš©    |
| `with_structured_output(schema)` | ëª¨ë¸ ì¶œë ¥ì„ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ íŒŒì‹± |
| `bind_tools(tools)`              | ë„êµ¬ í˜¸ì¶œì´ ê°€ëŠ¥í•œ ëª¨ë¸ë¡œ êµ¬ì„±   |
| `configurable_fields()`          | ëŸ°íƒ€ì„ì— êµ¬ì„± ê°€ëŠ¥í•œ í•„ë“œ ì§€ì •   |
| `configurable_alternatives()`    | êµì²´ ê°€ëŠ¥í•œ ëª¨ë¸ ì •ì˜        |


---

## ğŸ“š í´ë˜ìŠ¤ ê³„ì¸µ êµ¬ì¡°

```plaintext
ChatOpenAI
 â””â”€â”€ BaseChatOpenAI
      â””â”€â”€ BaseChatModel
           â””â”€â”€ BaseLanguageModel
                â””â”€â”€ RunnableSerializable
                     â””â”€â”€ Runnable
```

## ğŸ§± 1. BaseChatModel

```python
class BaseChatModel(BaseLanguageModel[BaseMessage], ABC):
    @abstractmethod
    def _generate(
        self,
        messages: List[BaseMessage],
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> ChatResult:
        ...
```

- LangChainì˜ chat ê¸°ë°˜ ëª¨ë¸ ì¶”ìƒ í´ë˜ìŠ¤
- _generate() ë©”ì„œë“œë¥¼ í†µí•´ ì‹¤ì œ ëª¨ë¸ í˜¸ì¶œ êµ¬í˜„ì„ ìš”êµ¬
- invoke, __call__, stream, batch ë“±ì€ Runnableì„ í†µí•´ ìë™ ì œê³µë¨

## ğŸ§± 2. BaseChatOpenAI

```python
class BaseChatOpenAI(BaseChatModel, ABC):
    model_name: str
    temperature: float = 0.7
    max_tokens: Optional[int] = None
    ...
```

- OpenAI Chat ëª¨ë¸ì˜ ê³µí†µ ì†ì„±ì„ ì •ì˜í•œ ì¤‘ê°„ ì¶”ìƒ í´ë˜ìŠ¤
- BaseChatModelì„ ìƒì†í•˜ì—¬ êµ¬ì¡° í†µí•©
- _generate()ëŠ” ì—¬ì „íˆ êµ¬í˜„ë˜ì§€ ì•ŠìŒ â†’ ChatOpenAIì—ì„œ êµ¬í˜„

## ğŸ§± 3. ChatOpenAI êµ¬í˜„ ì˜ˆ

```python
class ChatOpenAI(BaseChatOpenAI):
    def _generate(
        self,
        messages: List[BaseMessage],
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> ChatResult:
        response = openai.ChatCompletion.create(
            model=self.model_name,
            messages=[m.to_dict() for m in messages],
            temperature=self.temperature,
            ...
        )
        content = response.choices[0].message["content"]
        message = AIMessage(content=content)
        return ChatResult(generations=[ChatGeneration(message=message)])
    
    @property
    def _llm_type(self) -> str:
        return "openai-chat"
```

- _generate() ë‚´ë¶€ì—ì„œ ì‹¤ì œ OpenAI API (openai.ChatCompletion.create)ë¥¼ í˜¸ì¶œ
- ì‘ë‹µì€ LangChainì˜ ChatResult, ChatGeneration, AIMessageë¡œ ë˜í•‘ë¨

---

## ğŸ§­ ì‹¤í–‰ íë¦„ ìš”ì•½

```python
llm = ChatOpenAI(...)
result = llm.invoke([HumanMessage(content="Hello")])
```


### ë‚´ë¶€ í˜¸ì¶œ ìŠ¤íƒ

```text
invoke() â†’ Runnable.invoke()
  â†’ _call_with_config(self._call)
    â†’ self._call(input)
      â†’ self._generate(messages)
        â†’ openai.ChatCompletion.create(...)
```

## ğŸ“ ì°¸ê³  ë§í¬

- [ğŸ“„ LangChain ê³µì‹ ê°€ì´ë“œ: Custom Chat Model](https://python.langchain.com/docs/how_to/custom_chat_model/)

--- 