# π§  OpenAI Embeddings ν•™μµ μ •λ¦¬

## π“ κ°μ”

`OpenAIEmbeddings`λ” LangChain λλ” OpenAI SDKμ—μ„ μ κ³µν•λ” ν΄λμ¤/κΈ°λ¥μΌλ΅, ν…μ¤νΈλ¥Ό λ²΅ν„°λ΅ λ³€ν™ν•μ—¬ κ²€μƒ‰, μ μ‚¬λ„ λΉ„κµ, λ¶„λ¥ λ“±μ— ν™μ©ν•  μ μκ² ν•©λ‹λ‹¤.

```python
from langchain_openai import OpenAIEmbeddings
```

---

## π“¦ μ£Όμ” νλΌλ―Έν„°

| νλΌλ―Έν„°                | μ„¤λ…                                                                |
| ------------------- | ----------------------------------------------------------------- |
| `model`             | μ„λ² λ”© λ¨λΈ μ΄λ¦„ (μ: `text-embedding-3-small`, `text-embedding-ada-002`) |
| `dimensions`        | μ¶λ ¥ λ²΅ν„°μ μ°¨μ› μ μ ν• (μ: 128, 256, 512, ...)                            |
| `openai_api_key`    | OpenAI API μΈμ¦ ν‚¤                                                   |
| `chunk_size`        | batch μ²λ¦¬ν•  λ¬Έμ¥ μ                                                    |
| `show_progress_bar` | μ²λ¦¬ μ§„ν–‰ λ°” ν‘μ‹ μ—¬λ¶€                                                     |


---

## π”§ μ£Όμ” λ©”μ„λ“

| λ©”μ„λ“                                 | μ„¤λ…                      |
| ----------------------------------- | ----------------------- |
| `embed_documents(texts: List[str])` | μ—¬λ¬ λ¬Έμ¥μ„ λ²΅ν„°λ΅ μ„λ² λ”©          |
| `embed_query(text: str)`            | λ‹¨μΌ μΏΌλ¦¬λ¥Ό λ²΅ν„°λ΅ μ„λ² λ”© (κ²€μƒ‰μ— μ‚¬μ©) |


---

## π― μ°¨μ›(dimensions)μ„ μ ν•ν•λ” μ΄μ 

| λ©μ      | μ„¤λ…                                |
| ------ | --------------------------------- |
| μ„±λ¥ μµμ ν™” | μ°¨μ› μκ°€ λ‚®μ„μλ΅ μ—°μ‚°μ΄ λΉ λ¦„, λ©”λ¨λ¦¬ μ μ         |
| λΉ„μ© μ κ°  | λ²΅ν„° μ €μ¥/λΉ„κµ λΉ„μ© κ°μ†                    |
| μ‹μ¤ν… νΈν™ | κΈ°μ΅΄ DB λλ” λ¨λΈκ³Ό νΈν™μ„ λ§μ¶”κΈ° μ„ν•¨           |
| ν’μ§ μ μ–΄  | ν•„μ” μ΄μƒμ μ°¨μ›μ€ μ •λ³΄ μ†μ‹¤λ³΄λ‹¤ μ¤νλ ¤ λ…Έμ΄μ¦ μ¦κ°€ κ°€λ¥μ„± |


---

## π§ μ‹¤ν—: λ‹¤μ–‘ν• μ°¨μ›λ³„ μ½”μ‚¬μΈ μ μ‚¬λ„ λΉ„κµ

### π“ ν…μ¤νΈ λ¬Έμ¥

- λ¬Έμ¥ A: "The quick brown fox jumps over the lazy dog."
- λ¬Έμ¥ B: "A fast dark-colored fox leaps over a sleepy dog."

### π“ κ²°κ³Ό

```markdown
   DIM | COSINE SIMILARITY
------------------------------
   128 | 0.72319
   256 | 0.76737
   512 | 0.76606
  1024 | 0.75479
  1536 | 0.75665
```

### π§  ν•΄μ„
- κ°€μ¥ λ†’μ€ μ μ‚¬λ„λ” 256μ°¨μ›μ—μ„ λ‚μ΄
- κ³ μ°¨μ›(1024, 1536)μ€ λ°λ“μ‹ λ” μΆ‹μ€ μ μ‚¬λ„λ¥Ό λ³΄μ¥ν•μ§€ μ•μ
- λ„λ¬΄ λ‚®μ€ μ°¨μ›(128)μ€ μ •λ³΄ μ†μ‹¤λ΅ μΈν•΄ μ μ‚¬λ„ μ €ν•
- μ μ ν• μ°¨μ› μλ” λ©μ κ³Ό ν™κ²½μ— λ”°λΌ 256~512κ°€ μΆ‹μ€ μ„ νƒμΌ μ μμ

---

## π“ μ‹κ°ν™” μμ‹ (Matplotlib)

```python
import matplotlib.pyplot as plt

dims = [128, 256, 512, 1024, 1536]
sims = [0.72319, 0.76737, 0.76606, 0.75479, 0.75665]

plt.plot(dims, sims, marker='o')
plt.title("Cosine Similarity vs Embedding Dimensions")
plt.xlabel("Dimensions")
plt.ylabel("Cosine Similarity")
plt.grid(True)
plt.show()
```

---

## π”— μ°Έκ³  μλ£

- [OpenAI κ³µμ‹ μ„λ² λ”© λ¬Έμ„](https://platform.openai.com/docs/guides/embeddings)
- [LangChain Embeddings κ°€μ΄λ“](https://python.langchain.com/docs/how_to/embed_text/)